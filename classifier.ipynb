{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1568182f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 09:38:35.748514: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 09:38:36.035449: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-11 09:38:36.077228: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-11 09:38:36.077273: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-11 09:38:37.078635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-11 09:38:37.078712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-11 09:38:37.078718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'keras.api._v2.keras.datasets.fashion_mnist'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "fasion_mnist=keras.datasets.fashion_mnist\n",
    "fasion_mnist.__name__ #returns a module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26b8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=fasion_mnist.load_data() #returns data splited in train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebabd4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train) #shapee (60000,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed153647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0],cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9b34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63cb130c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_model=keras.models.Sequential()\n",
    "seq_model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "seq_model.add(keras.layers.Dropout(rate=0.2))\n",
    "seq_model.add(keras.layers.Dense(300,activation=\"elu\"))\n",
    "seq_model.add(keras.layers.Dropout(rate=0.2))\n",
    "seq_model.add(keras.layers.Dense(100,activation=\"elu\"))\n",
    "seq_model.add(keras.layers.Dropout(rate=0.2))\n",
    "seq_model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5ebfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82af8fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00640519, -0.06981608,  0.06150359, ...,  0.04960368,\n",
       "        -0.05726685, -0.02539387],\n",
       "       [-0.06568036, -0.05435379, -0.04575212, ..., -0.07086296,\n",
       "        -0.0047284 , -0.0655036 ],\n",
       "       [-0.01337039,  0.05285607,  0.04641734, ..., -0.05381702,\n",
       "         0.00632314, -0.0107879 ],\n",
       "       ...,\n",
       "       [-0.01458114, -0.03103881, -0.06946176, ...,  0.05467658,\n",
       "         0.00240481,  0.02728336],\n",
       "       [-0.05324072,  0.03138614,  0.03944889, ...,  0.01346628,\n",
       "         0.02392476, -0.02066547],\n",
       "       [-0.01200074,  0.00180607, -0.01159793, ...,  0.0031677 ,\n",
       "         0.05665366, -0.01307166]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights,bias=seq_model.layers[2].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90274ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Nadam(learning_rate=10e-4),\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d78adbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 0.2982 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.2826 - val_sparse_categorical_accuracy: 0.8976\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2941 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.2982 - val_sparse_categorical_accuracy: 0.8928\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2898 - sparse_categorical_accuracy: 0.8899 - val_loss: 0.2864 - val_sparse_categorical_accuracy: 0.8986\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2908 - sparse_categorical_accuracy: 0.8904 - val_loss: 0.2891 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2893 - sparse_categorical_accuracy: 0.8898 - val_loss: 0.2763 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2831 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2912 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2809 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2870 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2811 - sparse_categorical_accuracy: 0.8921 - val_loss: 0.2720 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.2790 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.2905 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2776 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.2832 - val_sparse_categorical_accuracy: 0.9002\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2742 - sparse_categorical_accuracy: 0.8964 - val_loss: 0.2871 - val_sparse_categorical_accuracy: 0.8988\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2753 - sparse_categorical_accuracy: 0.8957 - val_loss: 0.2890 - val_sparse_categorical_accuracy: 0.8988\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2755 - sparse_categorical_accuracy: 0.8957 - val_loss: 0.2984 - val_sparse_categorical_accuracy: 0.8892\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2696 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.3049 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2733 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.2799 - val_sparse_categorical_accuracy: 0.9002\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2672 - sparse_categorical_accuracy: 0.8979 - val_loss: 0.2942 - val_sparse_categorical_accuracy: 0.8976\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2653 - sparse_categorical_accuracy: 0.8987 - val_loss: 0.3068 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2659 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.2879 - val_sparse_categorical_accuracy: 0.9004\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2637 - sparse_categorical_accuracy: 0.8987 - val_loss: 0.2787 - val_sparse_categorical_accuracy: 0.9010\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2632 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.3007 - val_sparse_categorical_accuracy: 0.8974\n"
     ]
    }
   ],
   "source": [
    "#lets train model on dataset but first lets create an validation set\n",
    "x_val,x_train_val=x_train[:5000]/256,x_train[5000:]/256 #if you dont divide by 256 it will not converge \n",
    "                                                        #diminishing gradients\n",
    "y_val,y_train_val=y_train[:5000],y_train[5000:]\n",
    "history=seq_model.fit(x_train_val,y_train_val,epochs=20,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a93c491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3257 - sparse_categorical_accuracy: 0.8866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32567572593688965, 0.8866000175476074]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled,y_test_scaled=x_test/256,y_test\n",
    "seq_model.evaluate(x_test_scaled,y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19a4b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_probas = np.stack([seq_model(x_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffbb7d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30632738214577976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "ans =log_loss(y_test_scaled,y_proba)\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
